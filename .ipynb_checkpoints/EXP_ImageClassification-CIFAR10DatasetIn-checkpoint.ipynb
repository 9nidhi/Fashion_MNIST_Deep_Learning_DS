{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9669478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import tensorflow as tf   \n",
    "from tensorflow.keras import datasets, layers, models\n",
    "# Display the version\n",
    "print(tf.__version__)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af195cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67707039",
   "metadata": {},
   "source": [
    "# perposerr cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be63982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Load the CIFAR-10 dataset\n",
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# # Display the shape of x_train and y_train\n",
    "# print(\"train_images shape:\", train_images.shape)\n",
    "# print(\"train_labels shape:\", train_labels.shape)\n",
    "# # print(\"database----------------------------------\",train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d66c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Step 2: Data Preprocessing\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert labels to one-hot encoded vectors\n",
    "# train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "# test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1049e9",
   "metadata": {},
   "source": [
    "# create deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16daed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Step 3: Model Architecture\n",
    "# model = models.Sequential([\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cddee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db274604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Compile the Model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e4b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Step 5: Training the Model\n",
    "# history = model.fit(train_images, train_labels, epochs=15, batch_size=64, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc711e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Get training and validation accuracy\n",
    "# train_acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# # Get training and validation loss\n",
    "# train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# # Plot training and validation accuracy values\n",
    "# plt.plot(train_acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training and validation loss values\n",
    "# plt.plot(train_loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d3715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert one-hot encoded labels back to categorical labels\n",
    "# true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# # Convert predictions to categorical labels\n",
    "# predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# # Calculate test accuracy\n",
    "# test_accuracy = np.mean(predicted_labels == true_labels)\n",
    "# print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# # Calculate test loss\n",
    "# from sklearn.metrics import log_loss\n",
    "# # Convert predictions and true labels to single-column format\n",
    "# test_loss = log_loss(true_labels, predictions)\n",
    "# print(\"Test Loss:\", test_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
